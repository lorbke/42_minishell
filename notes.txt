
----------TO DO---------------

- readline does not properly work in bash, because i have exported the readline libs and incs only in zsh, what should I do about it?

- autocompletion with tab
	- rl_replace_line will be helpful here

- include tester in the directory

- proper file structure?
	- no includes folder

- doxygen for documentation

- debugger
	- debug functions for every module that track whats going on

- subshell for every pipe!!

----------requirements----------

detailed list: https://docs.google.com/spreadsheets/d/e/2PACX-1vT4i9G61JSd0ertOLZsAsqvcUH_Dag3FZ5ERm26vLdXnKcJ-NtZctL4mmMCGp1SATtZvCKPbXUsTg5G/pubhtml



----------logic-------------

structure flowchart: https://lucid.app/lucidspark/6b5a618b-0bb7-4dbb-bef9-ecfa5268be38/edit?invitationId=inv_e9f761d2-aae8-446b-a770-ca45b661721d#

---specifics of error handling?
	- most of the syntax will be handled by execve
	- properly structure during implementation, so that returning to main and freeing is as simple as possible

---heredoc
	- where
		- heredoc input is opened in the executor (relatively similar to subshell, input will be gathered from the heredoc, which is then added to the parse tree)
	- https://pubs.opengroup.org/onlinepubs/9699919799/utilities/V3_chap02.html#tag_18_02

---signals
	- basically a bunch of non-static functions providing functionality for creating and changing signal handling, which has to be integrated into every relevant loop (prompt loop and heredoc loop)
	- signals = keys being pressed, signal handler = function that is called upon pressing
	- real shell seems to use trap to change how signals are handled during runtime
	- heredoc only edge case?

---environment variables
	- initialized from the environment
	- extern?
		- will import global variable from another file
	- passing to subshell?
		- copied and then passed as a parameter?

---subshells
	- tcgetattr, tcsetattr, isatty seem to be important here
	- why?
		- parallel computation
		- isolation of effects (such as changing envs)
	- when is it created?
		- in the executor
		- copying of envs
		- specific parameters when started 
	- how does it handle an already determined input (prompt skip)?
		- non-interactive shell

---Parse tree (dependency-based-parse-tree) https://en.wikipedia.org/wiki/Parse_tree
	- example in structure flowchart
	- tokens are parsed left-to-right, tokens have a precedence
	- when a token with a higher precedence than the one before appears, a rotation is performed (recursive pointer swap)
	- how are parenthesis represented in the tree?
		- everything in parenthesis is handled in a subshell, return value of subshell is represented as a token in the main tree
	- how are quotation marks represented in the tree?
		- these are already handled in the token list, everything in between quotes is a single token
	- how is precedence determined?
		- determined by the grammar
		- other parts of grammar are handled by simple if statements in the executor (e.g. &&-operator will stop execution after one element is true)
	- how is the tree structured exactly, so that the executor can execute in the correct order?
		- left-right recursion has to lead to the correct order, with special cases such as commands that are put first in the command table assembled by the executor

(---token types
	–Control operators (|, ||) 
	–Redirection operators (>, >>) 
	–Reserved words (while, if) 
	–Assignment tokens (foo=bar) 
	–Word tokens (everything else))

---WORD_DESC is a data struct used to pass information from one stage to next

---lexical analysis
	- basic unit = word
	- words are separated by metacharacters, (tab, space)
		- other special characters: double/single quotation mark, &&/||, /, pipe, >>/<</>/<, ($)?)
	- will "tokenize" these units according to grammar rules into a list structure
	- will identifiy tokens based on context and store ident in list
		- what identification categories are there? >> see bash source code repo, parser.h
		- identifiers/flags are stored as macros that represent a bit in an integer. The token list will contain an integer to represent all possible flags 
	- context-dependent analysis
		- categorizes words according to token type
	--> passes list to parser to be assembled into statements and commands
	---bash grammar
		- posix standard

---expander
	- expansion happens immediately before execution, iteratively for every single execution (because logical operands can change expansion output in between executions)
	- the word expansion loop resembles a pipeline: each iteration a possible expansion based on the flags is performed
		- this is important, since replication of bash's behaviour is the goal. The expansion therefore should happen in the same order as the original. This means that the flags also have to represent the same bits.


------debugging-------

- its sensible to replicate the bash debug behaviour
	- bash debugs using a DEBUG macro, just like pfuchs minishell does


-------PARSER----------

- recursive descent parser

(backus-naur-form (BNF) is a metasyntax notation, used to describe the syntax of a programming language)
BNF production rules: 
(source: https://stackoverflow.com/questions/71769632/making-a-shell-grammar-for-a-recursive-descent-parser)
	<all>        ::=  <and_or> <newline>
	<and_or>     ::=  <pipeline> { ('&&' | '||') <pipeline> }
	<pipeline>   ::=  <command> { '|' <command> }
	<comp_cmd>   ::=  ( <simple_cmd> | <and_or> )
	<simple_cmd> ::=  { ( <redirect> | <word> ) }
	<redirect>   ::=  ( '<' | '>' | '<<' | '>>' ) <word>
	<word>       ::=  ( any character except whitespace, metacharacters, or redirection operators )
{} = 0 or more
() = 1 of the options
 | = or
<> = reference to another production rule

	- quotes and parentheses (subshells) are not reflected by the grammar because they can appear anywhere

redirect
	- indirection <
		- file always on right side
	- outdirection >
		- file always on right side

approach:
	1. create function for each production rule
	2. manipulate the tree accordingly in the functions

example:
	echo hi | wc -l > out 
	complete_cmd
		and_or
			pipeline
				command
					simple_cmd
						word -> echo
						word -> hi
				command
					simple_cmd
						word -> wc
						word -> -l
					redirect -> >
					word -> out



		in

	<
			out
		>
			cat


--------EXECUTER--------


-----edge cases
	- simple_cmd
		- all redirection files are opened, including heredocs
		- only the last indirection/heredoc is used to be passed to the command
		- output is only redirected in the last outdirection file
		- if there is an outdirection and a pipe afterwards, the file is used as output and the pipe remains empty

	- pipeline
		- should right-hand incomplete pipes be handled?
			- actual bash will let you type in a command in that case
			- easy to implement

	- and_or
		- should the right-hand incomplete and/or be handled?
			- actual bash will let you type in a command in that case
			- easy to implement

- function for every token type
- every ast section contains at least one command
- the command (and its arguments) are returned up the call stack

- problem: the pipe out fd is not passed to the next command
- if instead the fd is returned, the problem is that the called function doesnt know the fd of the redirect file

--------executer solution:
	- every function returns a command table
	
	- a redirect calling function will overwrite the tables' in/out descriptor with its file and pass the table to its own calling function
	
	- a pipe calling function will create a pipe, and assigns the pipes write end to the out descriptor of the table if it is null, then executes the table's command and assembles a new table with the right-hand command of the pipe that is then passed to its own calling function
	
	- the initial calling function of the whole executor will therefore also be passed a command table, which it executes to complete execution

	- in the function that actually executes, variables are expanded and then quotes are removed

	remaining question:
		- a command in a command table can either be an actual command or a subshell?
		- during execution, the process is forked and either directly executes or first goes through the parser again to parse the subshell?
		- what is the output of a subshell? -> it has normal fds, just like regular commands, therefore this whole approach should work



-------TOKENIZER-------

Grammar:

	quotes
		- everything in between is a single token and considered a word (so it can be a command or a variable)
		- double quotes inside single quotes are ignored, including other type of quotes
		- no variable recognition or expansion for single quotes
		- variable recognition and expansion for double quotes
		- intra-word quotation: if quote is connected to a token, the token is part of the quote-token
			- intra-word quotation does not work on variables
		- quote-token is tried to be executed if it is in place of a command
		
		
		
		
		

SUBSHELL
- parenthesis always have to encompass a logically self-sufficient part of the input
	- counter argument: (<< stop) is a valid input, cat (<< stop) is not
	- theory has to be changed a bit
- in the ast, any rule can be replaced by a subshell?

- in the executor, this can be implemented by the called function passing back the whole subshell token and the calling function pipes or whatever, then uses an exec function to execute whatever it gets passed, inside the exec function it is determined if the passed object is a subshell or a simple command etc. and the exec function then acts accordingly









simple_cmd
	- while loop that checks if the next token is a word or a redirect, then sorts it into the correct place in the ast
		- problem: in and outdirect differentiation (has to be done anyway)
	- three separate lists for words, out- and indirections
	- at the end they are packed together

	- problem: how to handle the redirections?
		- more flags for the redirect functions?
	

	- there can be multiple indirections, but only from existing files
		- there can be multiple outdirections, but only to existing files






----------ERROR HANDLING----------

Parser
	- how to handle syntax errors?
		- seperate syntax module that iterates over the ast or the token list and checks for syntax errors
		- another approach would be to return NULL if a syntax error is encountered and handle it in the main parser function by saying "parse error near 'token'" where token is the next token in the stack

	- what errors are there?
		- syntax errors
		- parsing errors





CASE 25: (echo) hi
bash: syntax error near unexpected token `hi'

CASE 34: (< in) echo hi
bash: syntax error near unexpected token `echo'

solution:
	- a subshell can replace all words in a simple_cmd


CASE 32: < in (echo hi)
bash: syntax error near unexpected token `('





----------heredoc && unclosed------------

PSEUDO CODE:

digest_input
	tokstack = lexer(input)
	input = interpret_docs(tokstack, input)
	unclosed_quote_err(tokstack)
	ast = parser(tokstack)
	executer(ast)
>>> input

interpret_docs(tokstack, input)
	while tokstack
		if heredoc && tokstack->next
			tokstack->word = get_heredoc
		temp = tokstack
		tokstack->next
	if temp = unclosed_quote
			temp->word = get_quotedoc
			strjoin(input, quotedoc)
	else if is_incomplete(temp)
		temp->next = lexer(get_completingdoc)
		strjoin(input, completingdoc)
		input = interpret_docs(temp->next, input)
	return input

prepare_doc
	pipe
	fork
	parent
		read from pipe
	child
		doc routine

get_heredoc

get_quotedoc

get_completingdoc

- all docs use pipes
- the doc string is saved as the word of the ast node



--------------LEAKS--------------

- set of specific free functions
	- free_ast
	- free_tokstack
	- free_cmdtable(?)

- set of garbage collector functions
	- gc_malloc(type, size)
		- allocates pointer
		- calls gc_add_ptr
	- gc_add_ptr(ptr, *func_free)
		- adds pointer to static list of pointers
	- gc_free_all()
		- iterates through list
		- calls the free function of each pointer

- data types
	- struct garbage
		- ptr to allocated memory
		- ptr to free function
		- ptr to next node in list




----------LEXER------------

strsep
	str = skip_until_char(str, char skip)
	if (str == quote)


skip_subshell

skip_until_char(str, char skip)
	while *str && *str != skip
		str++
	return str + 1

lexer_str_to_tokstack
	head
	temp
	head = get_next_token(&str)
	if (!head)
		return NULL
	while (*str)
		temp->next = get_next_token(&str)
		if (!temp->next)
			break
	return head

get_next_word
	while *str == delim
		str++
	temp = str
	while *str
		if *str == quote
			str = skip_quote(str)
		else if (*str == subshell)
			str = skip_subshell(str)
			break
		else if *str == delim
			break
		else if *str == is_special_char
			break
		str++
	lexer_strdup(temp, str, str - temp)




----------REFACTORING------------

fn digest_input
	create tokstack

	get docs

	check subshell syntax

	check unclosed

	create ast

	check syntax

	execute

fn get_docs
	lexer tokstack
	check heredocs
	move to end of tokstack
	if last unclosed or incomplete
		get_docs
	- complete tokstack
	- complete input

------info
- doc termination
	- no error printed
- doc EOF and still invalid
	- unexpected end of file


| || case 